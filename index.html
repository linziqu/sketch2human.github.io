<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deep Human Generation with Disentangled Geometry and Appearance Constraints.">
  <meta name="keywords" content="Sketch2Human, StyleGAN">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Sketch2Human: Deep Human Generation with
    Disentangled Geometry and Appearance Constraints</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://github.com/linziqu/LinziQU.github.io">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Sketch2Human: Deep Human Generation with
            Disentangled Geometry and Appearance Constraints</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Linzi Qu</a><sup>1</sup>,</span>
            <span class="author-block">Jiaxiang Shang</a><sup>2</sup>,</span>
            <span class="author-block">Hui Ye</a><sup>2</sup>,
            </span>
            <span class="author-block">Xiaoguang Han</a><sup>3</sup>,
            </span>
            <span class="author-block">Hongbo Fu</a><sup>2</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup> City University of Hong Kong,</span>
            <span class="author-block"><sup>2</sup> Hong Kong University of Science and Technology,</span>
            <span class="author-block"><sup>3</sup> Chinese University of Hong Kong (Shenzhen)</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10538021&casa_token=hg1pgzRN2XAAAAAA:_r7-ZsL5rIVAMV2Zebdh2zKsjHPcOGVQe_tq5OtbAuSHqia0HV3_P76GFBSPF2kyNmoFay3kAiA&tag=1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2404.15889v1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!--<span class="link-block">
                <a href="https://github.com/linziqu/sketch2human.github.io/tree/main/Supplemental_material"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-solid fa-file"></i>
                  </span>
                  <span>Supplemental Material</span>
                </a>
              </span>-->
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>-->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/teaser.jpg" referrerpolicy="no-referrer" alt="Teaser">
      <h2 class="subtitle has-text-centered">
        Our Sketch2Human generates high-quality full-body images with respect to an input semantic sketch 
        for geometry control and a reference image for appearance control. (a), (b), (c), and (d) correspond to four different sketch inputs.
      </h2>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Geometry- and appearance-controlled full-body human image generation is an interesting but challenging task. 
            Existing solutions are either unconditional or dependent on coarse conditions (e.g., pose, text), thus lacking 
            explicit geometry and appearance control of body and garment. Sketching offers such editing ability and has been 
            adopted in various sketch-based face generation and editing solutions. However, directly adapting sketch-based 
            face generation to full-body generation often fails to produce high-fidelity and diverse results due to
            the high complexity and diversity in the pose, body shape, and garment shape and texture. Recent geometrically controllable
            diffusion-based methods mainly rely on prompts to generate appearance. It is hard to balance the realism and the faithfulness
            of their results to the sketch when the input is coarse. This work presents Sketch2Human, the first system for controllable
            full-body human image generation guided by a semantic sketch (for geometry control) and a reference image (for appearance
            control). Our solution is based on the latent space of StyleGAN-Human with inverted geometry and appearance latent codes as
            input. Specifically, we present a sketch encoder trained with a large synthetic dataset sampled from StyleGAN-Human's latent
            space and directly supervised by sketches rather than real images. Considering the entangled information of partial geometry and
            texture in StyleGAN-Human and the absence of disentangled datasets, we design a novel training scheme that creates 
            geometry-preserved and appearance-transferred training data to tune a generator to achieve disentangled geometry and appearance control. 
            Although our method is trained with synthetic data, it can also handle hand-drawn sketches. Qualitative and quantitative 
            evaluations demonstrate the superior performance of our method to state-of-the-art methods
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!--/ Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <img src="./static/images/framework.jpg" referrerpolicy="no-referrer" alt="Teaser">
        <h2 class="subtitle has-text-centered">
          Our Sketch2Human generates high-quality full-body images with respect to an input semantic sketch 
          for geometry control and a reference image for appearance control. (a), (b), (c), and (d) correspond to four different sketch inputs.
        </h2>
      </div>
    </div>
    <!--/ Method. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <video id="sketch2human" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/tvcg-sketch2human.mp4"
                  type="video/mp4">
        </video>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>



<!--/ More results. -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">More Results</h2>
    <div class="columns is-centered">
      <img src="./static/images/user_results_final.jpg" referrerpolicy="no-referrer" alt="Teaser">
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{qu2024sketch2human,
      title={Sketch2human: Deep human generation with disentangled geometry and appearance constraints},
      author={Qu, Linzi and Shang, Jiaxiang and Ye, Hui and Han, Xiaoguang and Fu, Hongbo},
      journal={IEEE Transactions on Visualization and Computer Graphics},
      year={2024},
      publisher={IEEE}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website source code based on the Nerfies project page. 
            If you want to reuse their <a href="https://github.com/nerfies/nerfies.github.io">source code</a>, please credit them appropriately.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
